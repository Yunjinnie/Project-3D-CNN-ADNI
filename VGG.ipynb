{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"VGG.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOwUFl4eugOLsbkf3/02M0n"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"hcUckPL-SSqm"},"outputs":[],"source":["class VGGBlock(nn.Module):\n","    def __init__(self, in_channels, out_channels,batch_norm=False):\n","\n","        super(VGGBlock,self).__init__()\n","\n","        conv2_params = {'kernel_size': (3, 3),\n","                        'stride'     : (1, 1),\n","                        'padding'   : 1\n","                        }\n","\n","        noop = lambda x : x\n","\n","        self._batch_norm = batch_norm\n","\n","        self.conv1 = nn.Conv2d(in_channels=in_channels,out_channels=out_channels , **conv2_params)\n","        self.bn1 = nn.BatchNorm2d(out_channels) if batch_norm else noop\n","\n","        self.conv2 = nn.Conv2d(in_channels=out_channels,out_channels=out_channels, **conv2_params)\n","        self.bn2 = nn.BatchNorm2d(out_channels) if batch_norm else noop\n","\n","        self.max_pooling = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n","\n","    @property\n","    def batch_norm(self):\n","        return self._batch_norm\n","\n","    def forward(self,x):\n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = F.relu(x)\n","\n","        x = self.conv2(x)\n","        x = self.bn2(x)\n","        x = F.relu(x)\n","\n","        x = self.max_pooling(x)\n","\n","        return x"]},{"cell_type":"code","source":["class VGG16(nn.Module):\n","\n","  def __init__(self, input_size, num_classes=1,batch_norm=False):\n","    super(VGG16, self).__init__()\n","\n","    self.in_channels,self.in_width,self.in_height = input_size\n","\n","    self.block_1 = VGGBlock(self.in_channels,64,batch_norm=batch_norm)\n","    self.block_2 = VGGBlock(64, 128,batch_norm=batch_norm)\n","    self.block_3 = VGGBlock(128, 256,batch_norm=batch_norm)\n","    self.block_4 = VGGBlock(256,512,batch_norm=batch_norm)\n","\n","  @property\n","  def input_size(self):\n","      return self.in_channels,self.in_width,self.in_height\n","\n","  def forward(self, x):\n","\n","    x = self.block_1(x)\n","    x = self.block_2(x)\n","    x = self.block_3(x)\n","    x = self.block_4(x)\n","\n","    return x"],"metadata":{"id":"6jSEoR6zScd9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class VGG16Classifier(nn.Module):\n","\n","  def __init__(self, num_classes=1,classifier = None,batch_norm=False):\n","    super(VGG16Classifier, self).__init__()\n","\n","\n","    self._vgg_a = VGG16((1,32,32),batch_norm=True)\n","    self._vgg_b = VGG16((1,32,32),batch_norm=True)\n","    self._vgg_star = VGG16((1,32,32),batch_norm=True)\n","    self.classifier = classifier\n","\n","    if (self.classifier is None):\n","        self.classifier = nn.Sequential(\n","          nn.Linear(2048, 2048),\n","          nn.ReLU(True),\n","          nn.Dropout(p=0.5),\n","          nn.Linear(2048, 512),\n","          nn.ReLU(True),\n","          nn.Dropout(p=0.5),\n","          nn.Linear(512, num_classes)\n","        )\n","\n","  def forward(self, x1,x2,x3):\n","      op1 = self._vgg_a(x1)\n","      op1 = torch.flatten(op1,1)\n","      op2 = self._vgg_b(x2)\n","      op2 = torch.flatten(op2,1)\n","      op3 = self._vgg_star(x3) \n","      op3 = torch.flatten(op3,1)\n","      \n","      x1 = self.classifier(op1)\n","      x2 = self.classifier(op2)\n","      x3 = self.classifier(op3)\n","\n","      return x1,x2,x3"],"metadata":{"id":"s2DT6rCJSesl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model1 = VGG16((1,32,32),batch_norm=True)\n","model2 = VGG16((1,32,32),batch_norm=True)\n","model_star = VGG16((1,32,32),batch_norm=True)\n","model_combo = VGG16Classifier(model1,model2,model_star)"],"metadata":{"id":"NyHikblGSf63"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class CombinedLoss(nn.Module):\n","    def __init__(self, loss_a, loss_b, loss_star, _lambda=1.0):\n","        super().__init__()\n","        self.loss_a = loss_a\n","        self.loss_b = loss_b\n","        self.loss_star = loss_star\n","\n","        self.register_buffer('_lambda',torch.tensor(float(_lambda),dtype=torch.float32))\n","\n","\n","    def forward(self,y_hat,y):\n","\n","        return (self.loss_a(y_hat[0],y[0]) + \n","                self.loss_b(y_hat[1],y[1]) + \n","                self.loss_combo(y_hat[2],y[2]) + \n","                self._lambda * torch.sum(model_star.weight - torch.pow(torch.cdist(model1.weight+model2.weight), 2)))"],"metadata":{"id":"e_bU3cMmShyv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train(net, loaders, optimizer, criterion, epochs=20, dev=None, save_param=False, model_name=\"valerio\"):\n","      loaders_a, loaders_b, loaders_star = loaders\n","    # try:\n","      net = net.to(dev)\n","      #print(net)\n","      #summary(net,[(net.in_channels,net.in_width,net.in_height)]*2)\n","\n","\n","      criterion.to(dev)\n","\n","\n","      # Initialize history\n","      history_loss = {\"train\": [], \"val\": [], \"test\": []}\n","      history_accuracy_a = {\"train\": [], \"val\": [], \"test\": []}\n","      history_accuracy_b = {\"train\": [], \"val\": [], \"test\": []}\n","      history_accuracy_star = {\"train\": [], \"val\": [], \"test\": []}\n","      # Store the best val accuracy\n","      best_val_accuracy = 0\n","\n","      # Process each epoch\n","      for epoch in range(epochs):\n","        # Initialize epoch variables\n","        sum_loss = {\"train\": 0, \"val\": 0, \"test\": 0}\n","        sum_accuracy_a = {\"train\": 0, \"val\": 0, \"test\": 0}\n","        sum_accuracy_b = {\"train\": 0, \"val\": 0, \"test\": 0}\n","        sum_accuracy_star = {\"train\": 0, \"val\": 0, \"test\": 0}\n","\n","        progbar = None\n","        # Process each split\n","        for split in [\"train\", \"val\", \"test\"]:\n","          if split == \"train\":\n","            net.train()\n","            #widgets = [\n","              #' [', pb.Timer(), '] ',\n","              #pb.Bar(),\n","              #' [', pb.ETA(), '] ', pb.Variable('ta','[Train Acc: {formatted_value}]')]\n","\n","            #progbar = pb.ProgressBar(max_value=len(loaders_a[split]),widgets=widgets,redirect_stdout=True)\n","\n","          else:\n","            net.eval()\n","          # Process each batch\n","          for j, ((input_a, labels_a), (input_b, labels_b), (input_s, labels_s)) in enumerate(zip(loaders_a[split], loaders_b[split], loaders_star[split])):\n","            labels_a = labels_a.unsqueeze(1).float()\n","            labels_b = labels_b.unsqueeze(1).float()\n","            labels_s = labels_s.unsqueeze(1).float()\n","\n","            input_a = input_a.to(dev)\n","            labels_a = labels_a.to(dev)\n","            input_b = input_b.to(dev)\n","            labels_b = labels_b.to(dev)\n","            input_s = input_s.to(dev)\n","            labels_s = labels_s.to(dev)\n","\n","            # Reset gradients\n","            optimizer.zero_grad()\n","            # Compute output\n","            pred = net(input_a,input_b, input_s)\n","\n","            loss = criterion(pred, [labels_a, labels_b, labels_s])\n","            # Update loss\n","            sum_loss[split] += loss.item()\n","            # Check parameter update\n","            if split == \"train\":\n","              # Compute gradients\n","              loss.backward()\n","              # Optimize\n","              optimizer.step()\n","\n","            # Compute accuracy\n","            pred_labels = (pred[2] >= 0.0).long()  # Binarize predictions to 0 and 1\n","            pred_labels_a = (pred[0] >= 0.0).long()  # Binarize predictions to 0 and 1\n","            pred_labels_b = (pred[1] >= 0.0).long()  # Binarize predictions to 0 and 1\n","\n","\n","            batch_accuracy_star = (pred_labels == labels_s).sum().item() / len(labels_s)\n","            batch_accuracy_a = (pred_labels_a == labels_a).sum().item() / len(labels_a)\n","            batch_accuracy_b = (pred_labels_b == labels_b).sum().item() / len(labels_b)\n","            # Update accuracy\n","            sum_accuracy_star[split] += batch_accuracy_star\n","            sum_accuracy_a[split] += batch_accuracy_a\n","            sum_accuracy_b[split] += batch_accuracy_b\n","\n","            #if (split=='train'):\n","              #progbar.update(j, ta=batch_accuracy)\n","              #progbar.update(j, ta=batch_accuracy_a)\n","              #progbar.update(j, ta=batch_accuracy_b)\n","\n","        #if (progbar is not None):\n","          #progbar.finish()\n","        # Compute epoch loss/accuracy\n","        #for split in [\"train\", \"val\", \"test\"]:\n","          #epoch_loss = sum_loss[split] / (len(loaders_a[split])+len(loaders_b[split])) \n","          #epoch_accuracy_combo = {split: sum_accuracy_combo[split] / len(loaders[split]) for split in [\"train\", \"val\", \"test\"]}\n","          #epoch_accuracy_a = sum_accuracy_a[split] / len(loaders_a[split])\n","          #epoch_accuracy_b = sum_accuracy_b[split] / len(loaders_b[split])\n","        epoch_loss = sum_loss[\"train\"] / (len(loaders_a[\"train\"])+len(loaders_b[\"train\"])+len(loaders_s[\"train\"])) \n","        epoch_accuracy_a = sum_accuracy_a[\"train\"] / len(loaders_a[\"train\"])\n","        epoch_accuracy_b = sum_accuracy_b[\"train\"] / len(loaders_b[\"train\"])\n","        epoch_accuracy_star = sum_accuracy_star[\"train\"] / len(loaders_s[\"train\"]) \n","\n","        epoch_loss_val = sum_loss[\"val\"] / (len(loaders_a[\"val\"])+len(loaders_b[\"val\"])+len(loaders_s[\"val\"])) \n","        epoch_accuracy_a_val = sum_accuracy_a[\"val\"] / len(loaders_a[\"val\"])\n","        epoch_accuracy_b_val = sum_accuracy_b[\"val\"] / len(loaders_b[\"val\"])\n","        epoch_accuracy_star_val = sum_accuracy_star[\"val\"] / len(loaders_s[\"val\"]) \n","\n","        epoch_loss_test = sum_loss[\"test\"] / (len(loaders_a[\"test\"])+len(loaders_b[\"test\"])+len(loaders_s[\"test\"])) \n","        epoch_accuracy_a_test = sum_accuracy_a[\"test\"] / len(loaders_a[\"test\"])\n","        epoch_accuracy_b_test = sum_accuracy_b[\"test\"] / len(loaders_b[\"test\"])\n","        epoch_accuracy_star_test = sum_accuracy_star[\"test\"] / len(loaders_s[\"test\"]) \n","\n","\n","        # Store params at the best validation accuracy\n","        if save_param and epoch_accuracy[\"val\"] > best_val_accuracy:\n","          # torch.save(net.state_dict(), f\"{net.__class__.__name__}_best_val.pth\")\n","          torch.save(net.state_dict(), f\"{model_name}_best_val.pth\")\n","          best_val_accuracy = epoch_accuracy[\"val\"]\n","\n","        # Update history\n","        for split in [\"train\", \"val\", \"test\"]:\n","          history_loss[split].append(epoch_loss)\n","          history_accuracy_a[split].append(epoch_accuracy_a)\n","          history_accuracy_b[split].append(epoch_accuracy_b)\n","          history_accuracy_star[split].append(epoch_accuracy_star)\n","        # Print info\n","        print(f\"Epoch {epoch + 1}:\",\n","              f\"Training Loss = {epoch_loss:.4f},\",)\n","        print(f\"Epoch {epoch + 1}:\",\n","              f\"Training Accuracy for A = {epoch_accuracy_a:.4f},\")\n","        print(f\"Epoch {epoch + 1}:\",\n","              f\"Training Accuracy for B = {epoch_accuracy_b:.4f},\")\n","        print(f\"Epoch {epoch + 1}:\",\n","              f\"Training Accuracy for star = {epoch_accuracy_star:.4f},\")\n","        \n","        print(f\"Epoch {epoch + 1}:\",\n","              f\"Val Loss = {epoch_loss_val:.4f},\",)\n","        print(f\"Epoch {epoch + 1}:\",\n","              f\"Val Accuracy for A = {epoch_accuracy_a_val:.4f},\")\n","        print(f\"Epoch {epoch + 1}:\",\n","              f\"Val Accuracy for B = {epoch_accuracy_b_val:.4f},\")\n","        print(f\"Epoch {epoch + 1}:\",\n","              f\"Val Accuracy for star = {epoch_accuracy_star_val:.4f},\")\n","        \n","        print(f\"Epoch {epoch + 1}:\",\n","              f\"Test Loss = {epoch_loss_test:.4f},\",)\n","        print(f\"Epoch {epoch + 1}:\",\n","              f\"Test Accuracy for A = {epoch_accuracy_a_test:.4f},\")\n","        print(f\"Epoch {epoch + 1}:\",\n","              f\"Test Accuracy for B = {epoch_accuracy_b_test:.4f},\")\n","        print(f\"Epoch {epoch + 1}:\",\n","              f\"Test Accuracy for star = {epoch_accuracy_star_test:.4f},\")\n","        print(\"\\n\")"],"metadata":{"id":"VR65Wkm-SlI2"},"execution_count":null,"outputs":[]}]}